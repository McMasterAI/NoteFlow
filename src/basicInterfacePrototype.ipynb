{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y5n6COwaPSc",
        "outputId": "3145a309-db13-43ff-8119-19a13df38dda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "from spacy.tokens import Span\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import re\n",
        "\n",
        "def boldItalicize(text, bullet_points):\n",
        "    # Determines keywords based on bullets in paragraph form , and applies them to the bullet points\n",
        "\n",
        "    bold_phrases = []\n",
        "    custom_stop_words = []\n",
        "\n",
        "    # with open(\"texts.txt\") as file:\n",
        "    #     text = file.read()\n",
        "\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.pos_ in [\"ADP\", \"PRON\"]:\n",
        "            custom_stop_words.append(token.text)\n",
        "\n",
        "    stop_words = set(custom_stop_words)\n",
        "\n",
        "    @spacy.registry.misc(\"stop_word_scrubber\")\n",
        "    def stop_word_scrubber():\n",
        "        def scrubber(span: Span) -> str:\n",
        "            while len(span) > 0 and span[0].text in stop_words:\n",
        "                span = span[1:]\n",
        "\n",
        "            return span.text\n",
        "        return scrubber\n",
        "\n",
        "    def identify_important_words():\n",
        "        important_words = set()\n",
        "\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ != \"DATE\":\n",
        "                important_words.add(ent.text)\n",
        "\n",
        "        return list(important_words)\n",
        "\n",
        "    # Example usage:\n",
        "    italicized_phrases = identify_important_words()\n",
        "\n",
        "    nlp.add_pipe(\"textrank\", config={\"scrubber\": {\"@misc\": \"stop_word_scrubber\"}})\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for key_term in doc._.phrases:\n",
        "        if key_term.rank > 0.06:\n",
        "            bold_phrases.append(key_term.text)\n",
        "\n",
        "\n",
        "    # Adding \"**\" & \"*\" around words based on \"bold_phrases\" and \"italized_phrases\"\n",
        "    bold_phrases.sort(key=len, reverse=True)\n",
        "    italicized_phrases.sort(key=len, reverse=True)\n",
        "\n",
        "    for i in range(len(bullet_points)):\n",
        "        for bold in bold_phrases:\n",
        "            pattern = re.compile(r'\\b' + re.escape(bold) + r'\\b')\n",
        "            bullet_points[i] = pattern.sub(f'**{bold}**', bullet_points[i])\n",
        "\n",
        "        for italics in italicized_phrases:\n",
        "            pattern = re.compile(r'\\b' + re.escape(italics) + r'\\b')\n",
        "            bullet_points[i] = pattern.sub(f'_{italics}_', bullet_points[i])\n",
        "\n",
        "\n",
        "    return bullet_points\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "\n",
        "text = \"Static variables belong to the class and are inherited by each object. This is good for things that are ubiquitous within all objects of a class. Static variables can still be used like non-static, to display specific information about an object, but the problem arises if you try and call them through the class, when there is no specific information available. This is where non-static comes in, since non-static cannot be called through the class, this problem goes away. Non-static is good for information that is specific to each class.\"\n",
        "text2 = \"We delved into the ethical considerations, focusing on accountability, transparency, and the potential bias embedded in algorithms. The transformative impact of AI across key sectors like healthcare, education, and business was a central theme, with an emphasis on both the opportunities and challenges these advancements present. The socio-economic implications were discussed, including the looming threat of job displacement and the urgent need for reskilling in the workforce. Real-world examples and case studies were examined to illustrate the dynamic relationship between AI and society, urging us to strike a delicate balance between innovation and ethical responsibility as we navigate this rapidly evolving technological landscape.\"\n",
        "text3 = \"The discussion began with an exploration of the geological conditions conducive to the creation of oil reserves. We focused on the organic matter, primarily ancient marine plants and microorganisms, that accumulates in sedimentary rock layers over millions of years. The lecture emphasized the significance of high pressure and temperature in these sedimentary basins, acting as catalysts for the transformation of organic material into hydrocarbons. The organic material undergoes a complex process known as diagenesis, involving the biochemical and physical changes that ultimately result in the formation of hydrocarbons, the building blocks of oil. As we delved deeper into the mechanisms of oil formation, the lecture highlighted the role of source rocks, migration pathways, and reservoir rocks in creating and preserving these valuable hydrocarbon deposits. Throughout the discussion, geological diagrams and cross-sections were used to illustrate the sequence of events leading to the development of oil reservoirs. The lecture concluded with an overview of exploration and extraction methods employed by the oil industry to tap into these reservoirs and meet the global demand for this essential energy resource.\"\n",
        "text4 = \"The discussion commenced with an overview of the fundamental principles underlying nuclear reactions. The focus was on the process of nuclear fission, wherein the nucleus of an atom splits into two or more smaller nuclei, releasing a significant amount of energy in the form of heat. The lecture then delved into the construction and operation of nuclear power plants, emphasizing the role of enriched uranium or plutonium as fuel sources. The concept of controlled chain reactions, essential for sustaining the energy release, was explained, highlighting the intricate balance required for safe and efficient operation. The applications of nuclear energy extended beyond electricity generation, as the lecture covered the use of nuclear technology in medical diagnostics and treatment, industrial processes, and even space exploration. The discussion also addressed the environmental considerations and safety measures associated with nuclear power, including the management of radioactive waste and the importance of stringent regulatory frameworks.\"\n",
        "text5 = \"The ship, boasting luxury and cutting-edge technology, set sail on a fateful night, April 14, 1912, when it collided with an iceberg. The ensuing chaos and disbelief among passengers and crew marked the beginning of an unraveling disaster. As the Titanic rapidly sank, lifeboats were in short supply, leading to both heroic tales of survival and heartbreaking losses. The tragedy left an indelible mark on maritime safety regulations, influencing a reassessment of practices to prevent future disasters. The sinking of the Titanic also became deeply ingrained in popular culture, inspiring numerous movies, books, and exhibits that continue to captivate the public's imagination. Archaeological discoveries of the wreckage have shed light on the events of that night, with ongoing efforts to preserve artifacts and document this poignant chapter in history. The human stories of survivors and victims, along with the stark social disparities on the ship, further contribute to the enduring legacy of the Titanic. Despite decades of exploration, ongoing mysteries persist, sparking debates about the role of design flaws and the insufficient number of lifeboats on that ill-fated journey. The Titanic remains a symbol of both tragedy and resilience, a story that continues to fascinate and resonate with people around the world.\"\n",
        "text6 = \"spaCy is able to compare two objects, and make a prediction of how similar they are. Predicting similarity is useful for building recommendation systems or flagging duplicates. For example, you can suggest a user content that’s similar to what they’re currently looking at, or label a support ticket as a duplicate if it’s very similar to an already existing one.\"\n",
        "text7 = \"Nuclear fission, a pivotal process in nuclear energy, unfolds when a neutron collides with the nucleus of a fissile atom, such as uranium-235 or plutonium-239, causing it to split into smaller nuclei and releasing a substantial amount of energy. This event triggers a chain reaction as the newly released neutrons go on to induce further fission reactions in neighboring nuclei. Control rods made of neutron-absorbing materials, like cadmium or boron, are strategically employed in nuclear reactors to regulate and maintain the rate of fission, preventing overheating. The heat generated is harnessed to produce steam, driving turbines connected to generators and ultimately generating electricity. This controlled process has become a cornerstone of global energy production, although ongoing research explores the potential of nuclear fusion as a cleaner and more sustainable alternative.\"\n",
        "text8 = \"The bourgeoisie, a concept deeply rooted in sociological theory, refers to the capitalist class that owns the means of production and controls economic resources within a society. Coined by Karl Marx, this term represents a social class characterized by its ownership of capital, such as factories and businesses, and its ability to accumulate wealth through the exploitation of labor. In the sociological framework, the bourgeoisie holds a position of power and influence, shaping economic structures and policies to maintain its interests. The concept emphasizes the dichotomy between the bourgeoisie and the proletariat, the working class, highlighting the inherent class struggle within capitalist societies. From a sociological perspective, the bourgeoisie not only signifies economic dominance but also wields cultural and political influence, contributing to the perpetuation of social inequalities and class-based divisions. This lens allows sociologists to analyze the dynamics of power, class conflict, and social change within the broader context of capitalist societies.\"\n",
        "\n",
        "def generateTitle(text):\n",
        "    nlp_tr = spacy.load(\"en_core_web_sm\")\n",
        "    nlp_post = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "    nlp_tr.add_pipe(\"textrank\")\n",
        "    doc = nlp_tr(text)\n",
        "\n",
        "    top_three_raw = []\n",
        "    title = []\n",
        "\n",
        "    #for phrase in doc._.phrases:\n",
        "        #print(phrase.text)\n",
        "        #print(phrase.rank, phrase.count)\n",
        "        #print(phrase.chunks)\n",
        "\n",
        "    for index, phrase in enumerate(doc._.phrases):\n",
        "        #print(phrase.text)\n",
        "        #print(phrase.rank, phrase.count)\n",
        "        #print(phrase.chunks)\n",
        "\n",
        "        if (index == 5):\n",
        "            break\n",
        "\n",
        "        title = [phrase.text,phrase.rank]\n",
        "\n",
        "        temp_doc = nlp_post(phrase.text)\n",
        "        for token in temp_doc:\n",
        "            if (token.shape_[0] == \"X\"):\n",
        "                title[1] += 1\n",
        "\n",
        "        top_three_raw.append(title)\n",
        "\n",
        "    top_three = sorted(top_three_raw, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    compare1 = nlp_post(top_three[0][0])\n",
        "    compare2 = nlp_post(top_three[1][0])\n",
        "    compare3 = nlp_post(top_three[2][0])\n",
        "\n",
        "    #print(\"\\n** Top Three Results **\")\n",
        "    #print(\"1. \" + top_three[0][0], top_three[0][1])\n",
        "    #print(\"2. \" + top_three[1][0], top_three[1][1])\n",
        "    #print(\"3. \" + top_three[2][0], top_three[2][1])\n",
        "    #print(top_three[0][0], \"<->\", top_three[1][0], compare1.similarity(compare2))\n",
        "    #print(top_three[1][0], \"<->\", top_three[2][0], compare2.similarity(compare3))\n",
        "    #print(top_three[0][0], \"<->\", top_three[2][0], compare1.similarity(compare3))\n",
        "    average = (compare1.similarity(compare2) + compare2.similarity(compare3) + compare1.similarity(compare3))/3\n",
        "    #print(\"Average similarity: \", average)\n",
        "\n",
        "    title = \"\\n#### \" + top_three[0][0] + \": \" + top_three[1][0] + \" & \" + top_three[2][0]\n",
        "    if (top_three[0][1] > 1):\n",
        "        picked_confidence = top_three[0][1] - 0.8\n",
        "    else:\n",
        "        picked_confidence = top_three[0][1]\n",
        "    print(\"\\nTitle Confidence:\", (picked_confidence + average)/1.1)\n",
        "    return title\n",
        "\n"
      ],
      "metadata": {
        "id": "16zz_BckaTca"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def generate_summary(text, model, tokenizer, l):\n",
        "    m = max(l, 1892)\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=m, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=(m/4), length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def to_bullet_points(summary):\n",
        "    sentences = summary.split(\". \")\n",
        "    bullet_points = [\"- \" + sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return bullet_points\n",
        "\n",
        "def main(input_text):\n",
        "    # Load\n",
        "    model_name = \"t5-base\"\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # ADD HERE\n",
        "    #input_text = \"Coined by Karl Marx, the bourgeoisie represents a social class characterized by its ownership of capital, such as factories and businesses, and its ability to accumulate wealth through the exploitation of labor. In the sociological framework, the bourgeoisie holds a position of power and influence, shaping economic structures and policies to maintain its interests. The concept emphasizes the dichotomy between the bourgeoisie and the proletariat, the working class, highlighting the inherent class struggle within capitalist societies. From a sociological perspective, the bourgeoisie not only signifies economic dominance but also wields cultural and political influence, contributing to the perpetuation of social inequalities and class-based divisions. This lens allows sociologists to analyze the dynamics of power, class conflict, and social change within the broader context of capitalist societies.\"\n",
        "\n",
        "    # Generate summary\n",
        "    summary = generate_summary(input_text, model, tokenizer, len(input_text))\n",
        "\n",
        "    # summary to bullet points\n",
        "    bullet_points = to_bullet_points(summary)\n",
        "\n",
        "    return (bullet_points)\n",
        "\n",
        "\n",
        "#print(main(\"Coined by Karl Marx, the bourgeoisie represents a social class characterized by its ownership of capital, such as factories and businesses, and its ability to accumulate wealth through the exploitation of labor. In the sociological framework, the bourgeoisie holds a position of power and influence, shaping economic structures and policies to maintain its interests. The concept emphasizes the dichotomy between the bourgeoisie and the proletariat, the working class, highlighting the inherent class struggle within capitalist societies. From a sociological perspective, the bourgeoisie not only signifies economic dominance but also wields cultural and political influence, contributing to the perpetuation of social inequalities and class-based divisions. This lens allows sociologists to analyze the dynamics of power, class conflict, and social change within the broader context of capitalist societies.\"))"
      ],
      "metadata": {
        "id": "sIZhSf_8adMt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input(\"Enter text to summarize: \")\n",
        "\n",
        "bullet_points = main(input_text)\n",
        "paragraphed_points = \" \".join(bullet_points).replace(\" -\",\".\").replace(\"- \",\"\")\n",
        "title = generateTitle(input_text)\n",
        "bullet_points = boldItalicize(paragraphed_points, bullet_points)\n",
        "\n",
        "print(title)\n",
        "print(\"\\n\".join(bullet_points))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y_Wt10jahsS",
        "outputId": "a1c7a15f-d8ca-4374-a7d8-dc99e71606b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter text to summarize: Coined by Karl Marx, the bourgeoisie represents a social class characterized by its ownership of capital, such as factories and businesses, and its ability to accumulate wealth through the exploitation of labor. In the sociological framework, the bourgeoisie holds a position of power and influence, shaping economic structures and policies to maintain its interests. The concept emphasizes the dichotomy between the bourgeoisie and the proletariat, the working class, highlighting the inherent class struggle within capitalist societies. From a sociological perspective, the bourgeoisie not only signifies economic dominance but also wields cultural and political influence, contributing to the perpetuation of social inequalities and class-based divisions. This lens allows sociologists to analyze the dynamics of power, class conflict, and social change within the broader context of capitalist societies.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title Confidence: 0.7131938631107894\n",
            "\n",
            "#### class conflict: social inequalities & social change\n",
            "- the **bourgeoisie** represents a **social class** characterized by its ownership of **capital**\n",
            "- the concept emphasizes the dichotomy between the **bourgeoisie** and the proletariat\n",
            "- the **bourgeoisie** wields **cultural and political influence**, contributing to **social inequalities**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import spacy.cli\n",
        "#spacy.cli.download(\"en_core_web_lg\")\n",
        "#nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVZV-dIqan3P",
        "outputId": "b24e2b12-1e35-4240-a5c9-8823c4fee41c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(notes):\n",
        "  bullet_points = main(notes)\n",
        "  paragraphed_points = \" \".join(bullet_points).replace(\" -\",\".\").replace(\"- \",\"\")\n",
        "  title = generateTitle(notes)\n",
        "  bullet_points = boldItalicize(paragraphed_points, bullet_points)\n",
        "  output = title + \"\\n\" + \"\\n\".join(bullet_points)\n",
        "  return output\n",
        "\n",
        "demo = gr.Interface(fn=greet,\n",
        "                    inputs=[\"textbox\"],\n",
        "                    outputs=gr.Markdown()\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "qjxFd8eibL1p",
        "outputId": "2fee8958-5956-45da-c587-eb7963e90888"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://1dbd42d418f70e280e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1dbd42d418f70e280e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xeXoi4uf8G4",
        "outputId": "762eef71-b9df-4ab2-da0c-9b4bfb9346f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.19.2-py3-none-any.whl (16.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.10.1 (from gradio)\n",
            "  Downloading gradio_client-0.10.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.2.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.10.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.10.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=dfbf66fa3b840f6025687266c8e580b38791a6fb23cdca3e321114e6ccd8a258\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.19.2 gradio-client-0.10.1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.2.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.27.1 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FQOPdWEf_QH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}